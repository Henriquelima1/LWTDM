{
    "name": "sr_lwtdm",
    "phase": "train",
    "gpu_ids": [
        0
    ],
    "path": {
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": null
        // "resume_state": "experiments/sr_lwtdm_XXXXXX_XXXXXX/checkpoint/IXEX" //pretrain model or training state
    },
    "datasets": {
        "train": {
            "name": "AID",
            "mode": "HR",
            "dataroot": "dataset/AID_28_224",
            "datatype": "img",
            "l_resolution": 28,
            "r_resolution": 224,
            "batch_size": 16,
            "num_workers": 8,
            "use_shuffle": true,
            "data_len": -1
        },
        "val": {
            "name": "RSSCN7",
            "mode": "LRHR",
            "dataroot": "dataset/RSSCN7val_28_224",
            "datatype": "img",
            "l_resolution": 28,
            "r_resolution": 224,
            "data_len": 3
        }
    },
    "model": {
        "which_model_G": "lwtdm",
        "finetune_norm": false,
        "net": {
            "in_channel": 3,
            "out_channel": 3,
            "inner_channel": 32,          // 64 or 128
            "channel_multiplier": [8],    // [1,1] or [2,2] or [1] or [2]
            "attn_res": 2,                // 4 or 6 or 8
            "res_blocks": 2,
            "dropout": 0.2
        },
        "beta_schedule": {
            "train": {
                "schedule": "linear",
                "n_timestep": 2000,
                "linear_start": 1e-4,
                "linear_end": 2e-2
            },
            "val": {
                "schedule": "linear",
                "n_timestep": 2000,
                "linear_start": 1e-4,
                "linear_end": 2e-2,
                "sampling_timesteps": 2000,
                "ddim_sampling_eta": 0.0
            }
        },
        "diffusion": {
            "image_size": 224,
            "channels": 3,
            "conditional": true
        }
    },
    "train": {
        "n_iter": 2000000,
        "val_freq": 1e5,
        "save_checkpoint_freq": 1e5,
        "print_freq": 200,
        "optimizer": {
            "type": "adam",
            "lr": 1e-4
        },
        "ema_scheduler": {
            "step_start_ema": 5000,
            "update_ema_every": 1,
            "ema_decay": 0.9999
        }
    },
    "wandb": {
        "project": "sr_lwtdm"
    }
}